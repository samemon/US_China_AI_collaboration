{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f756962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eabc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top5_conferences_google = ['neural information processing systems',\n",
    "                     'international conference on learning representations',\n",
    "                     'international conference on machine learning',\n",
    "                     'national conference on artificial intelligence',\n",
    "                     'international joint conference on artificial intelligence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554886c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining fontsizes for figures\n",
    "\n",
    "tick_fontsize = 10\n",
    "label_fontsize = 12\n",
    "title_fontsize = 12\n",
    "legend_fontsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a0bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.read_csv(\"data/figure4_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d9f41",
   "metadata": {},
   "source": [
    "## Percentage difference in the number of papers published in top conferences between US+China collaboration vs. not US+China\n",
    "\n",
    "Logic here is:\n",
    "\n",
    "1. Percentage of US-China collaboration papers that are published in top conferences \n",
    "2. Percentage of not US-China collaboration papers that are published in top conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43450a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>PubYear</th>\n",
       "      <th>us_china_collab</th>\n",
       "      <th>JID</th>\n",
       "      <th>CSID</th>\n",
       "      <th>JournalNameNorm</th>\n",
       "      <th>ConferenceNameNorm</th>\n",
       "      <th>Venue</th>\n",
       "      <th>analysis_type</th>\n",
       "      <th>CollaborationType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>62217316</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.184914e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Conference on Artificial Intelligence</td>\n",
       "      <td>national conference on artificial intelligence</td>\n",
       "      <td>china_us</td>\n",
       "      <td>China-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>77289000</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.204000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International Joint Conference on Artificial I...</td>\n",
       "      <td>international joint conference on artificial i...</td>\n",
       "      <td>china_us</td>\n",
       "      <td>China-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>79405465</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.180663e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International Conference on Machine Learning</td>\n",
       "      <td>international conference on machine learning</td>\n",
       "      <td>china_us</td>\n",
       "      <td>China-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>89212421</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.184914e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Conference on Artificial Intelligence</td>\n",
       "      <td>national conference on artificial intelligence</td>\n",
       "      <td>china_us</td>\n",
       "      <td>China-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>93018862</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.204000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International Joint Conference on Artificial I...</td>\n",
       "      <td>international joint conference on artificial i...</td>\n",
       "      <td>china_us</td>\n",
       "      <td>China-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PID  PubYear  us_china_collab  JID          CSID JournalNameNorm  \\\n",
       "106  62217316     2013                1  NaN  1.184914e+09             NaN   \n",
       "128  77289000     2013                1  NaN  1.204000e+09             NaN   \n",
       "132  79405465     2010                1  NaN  1.180663e+09             NaN   \n",
       "144  89212421     2011                1  NaN  1.184914e+09             NaN   \n",
       "148  93018862     2011                1  NaN  1.204000e+09             NaN   \n",
       "\n",
       "                                    ConferenceNameNorm  \\\n",
       "106     National Conference on Artificial Intelligence   \n",
       "128  International Joint Conference on Artificial I...   \n",
       "132       International Conference on Machine Learning   \n",
       "144     National Conference on Artificial Intelligence   \n",
       "148  International Joint Conference on Artificial I...   \n",
       "\n",
       "                                                 Venue analysis_type  \\\n",
       "106     national conference on artificial intelligence      china_us   \n",
       "128  international joint conference on artificial i...      china_us   \n",
       "132       international conference on machine learning      china_us   \n",
       "144     national conference on artificial intelligence      china_us   \n",
       "148  international joint conference on artificial i...      china_us   \n",
       "\n",
       "    CollaborationType  \n",
       "106          China-US  \n",
       "128          China-US  \n",
       "132          China-US  \n",
       "144          China-US  \n",
       "148          China-US  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenated_top = df_concatenated[df_concatenated.Venue.isin(top5_conferences_google)]\n",
    "\n",
    "df_concatenated_top.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d932df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the figure size in inches\n",
    "fig_width = 8.27 * (1/2)  # A4 width is 8.27 inches\n",
    "fig_height = 11.69 * (1/3)  # A4 height is 11.69 inches\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "# Create the bars\n",
    "ax.bar(0, \n",
    "       (df_concatenated_top.groupby(['us_china_collab','analysis_type'])\\\n",
    "        ['PID'].nunique()*100/df_concatenated.groupby(['us_china_collab','analysis_type'])['PID'].nunique())[1]['us_china'], \n",
    "       color='#377eb8', \n",
    "       label='US-China')\n",
    "\n",
    "ax.bar(1, \n",
    "       (df_concatenated_top.groupby(['us_china_collab','analysis_type'])\\\n",
    "        ['PID'].nunique()*100/df_concatenated.groupby(['us_china_collab','analysis_type'])['PID'].nunique())[0]['us_china'], \n",
    "       color='#8ac3f2', \n",
    "       label='US-notChina', hatch='//', alpha=0.5)\n",
    "\n",
    "ax.bar(2, \n",
    "       (df_concatenated_top.groupby(['us_china_collab','analysis_type'])\\\n",
    "        ['PID'].nunique()*100/df_concatenated.groupby(['us_china_collab','analysis_type'])['PID'].nunique())[1]['china_us'], \n",
    "       color='#e41a1c', \n",
    "       label='China-US')\n",
    "\n",
    "ax.bar(3, \n",
    "       (df_concatenated_top.groupby(['us_china_collab','analysis_type'])\\\n",
    "        ['PID'].nunique()*100/df_concatenated.groupby(['us_china_collab','analysis_type'])['PID'].nunique())[0]['china_us'], \n",
    "       color='#f59899', \n",
    "       label='China-notUS', hatch='//', alpha=0.5)\n",
    "\n",
    "# Set the x-axis ticks and labels\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax.set_xticklabels(['US-China', 'US-¬China', 'China-US', 'China-¬US'], fontsize=tick_fontsize)\n",
    "ax.set_ylabel('% of papers in top conferences', fontsize=label_fontsize)  # Y-axis label\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a370d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's map each conference to an abbreviation\n",
    "\n",
    "venue_to_abbr = {'international joint conference on neural network':'IJCNN',\n",
    "                             'international conference on learning representations':'ICLR',\n",
    "                             'international conference on artificial intelligence and statistics':'AISTATS',\n",
    "                             'the journal of machine learning research': 'JMLR',\n",
    "                             'national conference on artificial intelligence': 'AAAI',\n",
    "                             'neural information processing systems': 'NeurIPS',\n",
    "                             'conference on learning theory': 'CLT',\n",
    "                             'international conference on machine learning': 'ICML',\n",
    "                             'robotics and autonomous systems':'Robotics and Autonomous Systems',\n",
    "                             'international joint conference on artificial intelligence': 'IJCAI',\n",
    "                             'expert systems with applications': 'Expert Systems with Applications',\n",
    "                             'engineering applications of artificial intelligence':'Engineering Applications of Artificial Intelligence',\n",
    "                             'ieee transactions on systems man and cybernetics':'IEEE Transactions on Systems, Man, and Cybernetics',\n",
    "                             'neural networks':'Neural Networks',\n",
    "                             'ieee transactions on neural networks': 'IEEE Transactions on Neural Networks',\n",
    "                             'ieee transactions on fuzzy systems': 'IEEE Transactions on Fuzzy Systems',\n",
    "                             'applied soft computing': 'Applied Soft Computing',\n",
    "                             'knowledge based systems': 'Knowledge-Based Systems',\n",
    "                             'neural computing and applications':'Neural Computing and Applications',\n",
    "                             'neurocomputing': 'Neurocomputing'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83266ad3",
   "metadata": {},
   "source": [
    "## Compare: (i) US-China, (ii) US not China, (iii) China-US, (iv) China not US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01853bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute (a)\n",
    "\n",
    "dfa = df_concatenated.groupby(['Venue', 'CollaborationType'])['PID'].nunique().reset_index()\\\n",
    "                    .rename(columns={'PID':'NumPapers'})\n",
    "\n",
    "dfb = df_concatenated.groupby(['CollaborationType'])['PID'].nunique().reset_index()\\\n",
    "                    .rename(columns={'PID':'TotalPapers'})\n",
    "\n",
    "dfc = dfa.merge(dfb, on=['CollaborationType'])\n",
    "\n",
    "dfc['share'] = dfc['NumPapers']*100/dfc['TotalPapers']\n",
    "\n",
    "\n",
    "\n",
    "# Now let us extract only data relevant for version 1\n",
    "df_relevant_v2 = dfc[dfc.Venue.isin(top5_conferences_google)]\\\n",
    "                        .sort_values(by=['Venue'])\n",
    "\n",
    "# Now we need to impute\n",
    "\n",
    "grouped = df_relevant_v2.groupby(['Venue'])\n",
    "\n",
    "required_groups = ['US-notChina', 'US-China', 'China-US', 'China-notUS']\n",
    "\n",
    "def add_flipped_rows(group):\n",
    "    if 'China-notUS' in group['CollaborationType'].values and 'China-US' in group['CollaborationType'].values and \\\n",
    "       'US-notChina' in group['CollaborationType'].values and 'US-China' in group['CollaborationType'].values:\n",
    "        return group\n",
    "    else:\n",
    "        missing_groups = set(required_groups) - set(group['CollaborationType'].values)\n",
    "        lst_dfs_groups = []\n",
    "        \n",
    "        for g in missing_groups:\n",
    "            flipped_group = group.copy()\n",
    "            flipped_group['CollaborationType'] = g\n",
    "            flipped_group['share'] = 0\n",
    "            flipped_group['NumPapers'] = 0\n",
    "            lst_dfs_groups.append(flipped_group)\n",
    "        \n",
    "        return pd.concat([group]+lst_dfs_groups, ignore_index=True)\n",
    "\n",
    "result_df = grouped.apply(add_flipped_rows).reset_index(drop=True)\n",
    "\n",
    "df = result_df.copy().sort_values(by=['Venue','CollaborationType'])\n",
    "# Mapping venues to abbreviations\n",
    "\n",
    "df['Venue'] = df['Venue'].replace(venue_to_abbr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by venue for better arrangement\n",
    "df = df.sort_values(by=['Venue'])\n",
    "\n",
    "# Create a figure with 10 subplots\n",
    "fig, axs = plt.subplots(5, 1, figsize=(5, 8))\n",
    "\n",
    "# Flatten the axs array for easier indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Define the font family for titles\n",
    "title_font = {'fontname':'Helvetica'}  # Change 'Arial' to the desired font family\n",
    "\n",
    "# Iterate over venues and create bar plots\n",
    "for i, (venue, ax) in enumerate(zip(df['Venue'].unique(), axs)):\n",
    "    venue_data = df[df['Venue'] == venue]\n",
    "    us_china = venue_data[venue_data['CollaborationType']=='US-China']\n",
    "    us_notchina = venue_data[venue_data['CollaborationType']=='US-notChina']\n",
    "\n",
    "    china_us = venue_data[venue_data['CollaborationType']=='China-US']\n",
    "    china_notus = venue_data[venue_data['CollaborationType']=='China-notUS']\n",
    "    #f59899 #8ac3f2\n",
    "    ax.bar(0, us_china['share'], color=\"#377eb8\", label='US-China')\n",
    "    ax.bar(1, us_notchina['share'], color=\"#8ac3f2\", label='US-¬China',hatch='//',alpha=0.5)\n",
    "    ax.bar(2, china_us['share'], color=\"#e41a1c\", label='China-US')\n",
    "    ax.bar(3, china_notus['share'], color=\"#f59899\", label='China-¬US',hatch='//',alpha=0.5)\n",
    "    \n",
    "    if len(venue.split()) > 3:\n",
    "        venue_parts = venue.split()\n",
    "        venue = '\\n'.join([ ' '.join(venue_parts[:len(venue_parts)//2]), ' '.join(venue_parts[len(venue_parts)//2:]) ])\n",
    "\n",
    "    ax.set_title(venue, fontsize=title_fontsize, fontname = 'monospace')\n",
    "    ax.set_xticks([0, 1, 2 ,3])\n",
    "    ax.set_xticklabels(['US-China', 'US-¬China', 'China-US', 'China-¬US'], fontsize=tick_fontsize)\n",
    "    #ax.set_ylim(0, 1)  # Adjust the y-axis limits as needed\n",
    "    # Remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add shared y-axis label\n",
    "fig.text(-0.01, 0.5, '% of papers in top conferences', va='center', rotation='vertical', fontsize=label_fontsize)  # Adjust position and fontsize as needed\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a795a9d",
   "metadata": {},
   "source": [
    "## Compare: (i) US-China, (ii) US not China, (iii) China-US, (iv) China not US across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let us compute (a)\n",
    "\n",
    "dfa = df_concatenated[df_concatenated.Venue.isin(top5_conferences_google)].groupby(['PubYear','CollaborationType'])\\\n",
    "                    ['PID'].nunique().reset_index()\\\n",
    "                    .rename(columns={'PID':'NumPapers'})\n",
    "\n",
    "# dfa = df_concatenated.groupby(['PubYear', 'us_china_collab'])['PID'].nunique().reset_index()\\\n",
    "#                     .rename(columns={'PID':'NumPapers'})\n",
    "\n",
    "dfa.shape, dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute (b)\n",
    "\n",
    "dfb = df_concatenated.groupby(['PubYear','CollaborationType'])\\\n",
    "                    ['PID'].nunique().reset_index()\\\n",
    "                    .rename(columns={'PID':'TotalPapers'})\n",
    "\n",
    "dfb.shape, dfb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b67726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we merge a and b\n",
    "\n",
    "dfc = dfa.merge(dfb, on=['CollaborationType','PubYear'], how='left')\n",
    "\n",
    "dfc.shape, dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc679b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us compute the share\n",
    "\n",
    "dfc['share'] = dfc['NumPapers']*100/dfc['TotalPapers']\n",
    "\n",
    "dfc.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us extract only data relevant for version 1\n",
    "df_relevant_v1 = dfc.sort_values(by=['PubYear'])\n",
    "\n",
    "df_relevant_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to impute\n",
    "\n",
    "\n",
    "grouped = df_relevant_v1.groupby(['PubYear'])\n",
    "\n",
    "required_groups = ['US-notChina', 'US-China', 'China-US', 'China-notUS']\n",
    "\n",
    "def add_flipped_rows(group):\n",
    "    if 'China-notUS' in group['CollaborationType'].values and 'China-US' in group['CollaborationType'].values and \\\n",
    "       'US-notChina' in group['CollaborationType'].values and 'US-China' in group['CollaborationType'].values:\n",
    "        return group\n",
    "    else:\n",
    "        missing_groups = set(required_groups) - set(group['CollaborationType'].values)\n",
    "        lst_dfs_groups = []\n",
    "        \n",
    "        for g in missing_groups:\n",
    "            flipped_group = group.copy()\n",
    "            flipped_group['CollaborationType'] = g\n",
    "            flipped_group['share'] = 0\n",
    "            flipped_group['NumPapers'] = 0\n",
    "            lst_dfs_groups.append(flipped_group)\n",
    "        \n",
    "        return pd.concat([group]+lst_dfs_groups, ignore_index=True)\n",
    "\n",
    "result_df = grouped.apply(add_flipped_rows).reset_index(drop=True)\n",
    "\n",
    "df = result_df.copy().sort_values(by=['PubYear','CollaborationType'])\n",
    "\n",
    "df = df[df.PubYear.le(2020)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create scatter plots\n",
    "scatter1 = ax.scatter(df[df.CollaborationType=='US-China'].PubYear, \n",
    "                      df[df.CollaborationType=='US-China'].share, s=50, color=\"#377eb8\", \n",
    "            label=\"US-China\")\n",
    "scatter2 = ax.scatter(df[df.CollaborationType=='US-notChina'].PubYear, \n",
    "                      df[df.CollaborationType=='US-notChina'].share, s=50, color=\"#8ac3f2\", \n",
    "            label=\"US-¬China\")\n",
    "\n",
    "scatter3 = ax.scatter(df[df.CollaborationType=='China-US'].PubYear, \n",
    "                      df[df.CollaborationType=='China-US'].share, s=50, color=\"#e41a1c\", \n",
    "            label=\"China-US\")\n",
    "scatter4 = ax.scatter(df[df.CollaborationType=='China-notUS'].PubYear, \n",
    "                      df[df.CollaborationType=='China-notUS'].share, s=50, color=\"#f59899\", \n",
    "            label=\"China-¬US\")\n",
    "\n",
    "\n",
    "# Connect the scatter plots with a line\n",
    "line1 = ax.plot(df[df.CollaborationType=='US-China'].PubYear.values, \n",
    "                df[df.CollaborationType=='US-China'].share.values, color='#377eb8')\n",
    "\n",
    "line2 = ax.plot(df[df.CollaborationType=='US-notChina'].PubYear.values, \n",
    "                df[df.CollaborationType=='US-notChina'].share.values, color='#8ac3f2')\n",
    "\n",
    "\n",
    "line3 = ax.plot(df[df.CollaborationType=='China-US'].PubYear.values, \n",
    "                df[df.CollaborationType=='China-US'].share.values, color='#e41a1c')\n",
    "\n",
    "line4 = ax.plot(df[df.CollaborationType=='China-notUS'].PubYear.values, \n",
    "                df[df.CollaborationType=='China-notUS'].share.values, color='#f59899')\n",
    "\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Year', fontsize=label_fontsize)\n",
    "ax.set_ylabel('% of papers in top conferences', fontsize=label_fontsize)\n",
    "\n",
    "# Set custom x-axis ticks and labels\n",
    "xticks = range(2000,2021,2)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks, fontsize=tick_fontsize)\n",
    "\n",
    "# Add legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, fancybox=True)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "# Show or save the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75d841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e610721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a2788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260bc04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656fb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9263fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
